{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cacedef6",
   "metadata": {},
   "source": [
    "## Reproducibility Project - SleepQA : A Health Coaching Dataset on sleep for Extractive Question Answering\n",
    "- Written by Kihyuk Song and Hyunkyung Lee\n",
    "- Subject: CS598 Deep Learning for Healthcare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a314c04",
   "metadata": {},
   "source": [
    "### 1. Citation to the original paper\n",
    "Iva Bojic, Qi Chwen Ong, Megh Thakkar, Esha Kamran, Irving Yu Le Shua, Rei Ern Jaime Pang, Jessica Chen, Vaaruni Nayak, Shafiq Joty, Josip Car. SleepQA: A Health Coaching Dataset on Sleep for Extractive Question Answering. Proceedings of Machine Learning for Health (ML4H) 2022 Workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb9c779",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Link to the original paperâ€™s repo\n",
    "https://github.com/IvaBojic/SleepQA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795992e2",
   "metadata": {},
   "source": [
    "### 3. Dependencies\n",
    "(1) Installation by pip\n",
    "\"pyserini\", \"faiss-cpu>=1.6.1\", \"filelock\", \"numpy\", \"regex\", \"torch>=1.5.0\", \"transformers>=4.3\", \"tqdm>=4.27\", \"wget\", \"spacy>=2.1.8\", \"hydra-core>=1.0.0\", \"omegaconf>=2.0.1\", \"jsonlines\", \"soundfile\", \"editdistance\"\n",
    "(2) Installation by apt-get\n",
    "openjdk-11-jdk, git-lfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de621e00",
   "metadata": {},
   "source": [
    "### 4. Data download instruction\n",
    "Datas are downloaded from https://github.com/IvaBojic/SleepQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cbf6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_train:\n",
    "  _target_: dpr.data.retriever_data.CsvQASrc\n",
    "  file: \"../../../../data/training/sleep-train.csv\"\n",
    "\n",
    "sleep_dev:\n",
    "  _target_: dpr.data.retriever_data.CsvQASrc\n",
    "  file: \"../../../../data/training/sleep-dev.csv\"\n",
    "\n",
    "sleep_test:\n",
    "  _target_: dpr.data.retriever_data.CsvQASrc\n",
    "  file: \"../../../../data/training/sleep-test.csv\"\n",
    "\n",
    "sleep_open:\n",
    "  _target_: dpr.data.retriever_data.CsvQASrc\n",
    "  file: \"../../../../data/training/open_questions.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9754c4f8",
   "metadata": {},
   "source": [
    "### 5. Preprocessing code + command \n",
    "I built the docker image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fff65d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dockerfile\n",
    "FROM nvcr.io/nvidia/pytorch:21.11-py3\n",
    "WORKDIR /data\n",
    "COPY SleepQA/DPR-main /data/SleepQA/DPR-main\n",
    "RUN pip install /data/SleepQA/DPR-main\n",
    "RUN python -m spacy download en_core_web_sm\n",
    "RUN pip install pyserini\n",
    "RUN apt-get update && apt-get install -y openjdk-11-jdk\n",
    "RUN apt-get install -y git-lfs\n",
    "CMD [\"/bin/bash\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c40dc",
   "metadata": {},
   "source": [
    "I created two containers using the image that can utilize 4 GPUs each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd7d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker build -t dpr-container .\n",
    "docker run --gpus=4 --name dpr01 -v /DATA/tmpdata_hk:/data -itd dpr-container \n",
    "docker run --gpus '\"device=4,5,6,7\"' --name dpr02 -v /DATA/tmpdata_hk:/data -itd dpr-container "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d7457b",
   "metadata": {},
   "source": [
    "### 6. Training code + command\n",
    "DPR (Dense Passage Retrieval) is a framework that efficiently searches for information in large amounts of text. The Biencoder in DPR consists of a question encoder and a document encoder, which each convert the question and document into vectors to identify highly relevant documents. The Extractive Reader then extracts accurate answers to questions based on the documents returned by the Biencoder. Both the question and document are used as inputs to extract the answer.\n",
    "I changed the hyperparameter from the yaml file of Biencoder and Extractive reader.\n",
    "I used two models such as BioBERT and ClinicialBERT.\n",
    "This stage is processed in `DPR-main` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5377bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### biencoder conf\n",
    "conf/biencoder_train_cfg.yaml\n",
    "  - encoder: hf_biobert, hf_clinicalBERT\n",
    "\n",
    "conf/train/biencoder_local.yaml\n",
    "  - dev_batch_size: 32 (previous value was 16)\n",
    "  - learning_rate: 2e-5\n",
    "  - num_train_epochs: 20 (previous value was 30)\n",
    "  \n",
    "### extractive reader conf\n",
    "conf/extractive_reader_train_cfg.yaml\n",
    "  - encoder: hf_biobert, hf_clinicalBERT\n",
    "\n",
    "conf/train/extractive_reader_default.yaml\n",
    "  - dev_batch_size: 32 (previous value was 16)\n",
    "  - learning_rate: 1e-5 (previous value was 2e-5)\n",
    "  - num_train_epochs: 20 (previous value was 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2378f5f",
   "metadata": {},
   "source": [
    "\n",
    "I ran the training of the models.\n",
    "I used the PyTorch to parallelize the computation across 4 GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6c2574",
   "metadata": {},
   "outputs": [],
   "source": [
    "### biencoder training\n",
    "python -m torch.distributed.launch --nproc_per_node=4 \\\n",
    "train_dense_encoder.py \\\n",
    "train=biencoder_local \\\n",
    "train_datasets=\"/data/SleepQA/data/training/sleep-train.json\" \\\n",
    "dev_datasets=\"/data/SleepQA/data/training/sleep-dev.json\" \\\n",
    "output_dir=\"train_dense_encoder/\"\n",
    "\n",
    "### extractive reader training\n",
    "python -m torch.distributed.launch --nproc_per_node=4 \\\n",
    "train_extractive_reader.py \\\n",
    "encoder.sequence_length=300 \\\n",
    "train_files=\"/data/SleepQA/data/training/oracle/sleep-train.json\" \\\n",
    "dev_files=\"/data/SleepQA/data/training/oracle/sleep-dev.json\"  \\\n",
    "output_dir=\"biobert/reader\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417693f1",
   "metadata": {},
   "source": [
    "### 7. Evaluation code + command \n",
    "I saved the results of inferencing from trained models.\n",
    "This stage is processed in `DPR-main` directory.\n",
    "First, I extracted feature vectors with the biencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bea9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "python generate_dense_embeddings.py \\\n",
    "    model_file=\"/data/SleepQA/DPR-main/outputs/2023-05-08/14-14-01/train_dense_encoder/dpr_biencoder.19\" \\\n",
    "    ctx_src=\"dpr_sleep\" \\\n",
    "    out_file=\"/data/SleepQA/models/processed/encoder-clinical\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bcb201",
   "metadata": {},
   "source": [
    "Next, I searched for questions and save the results in a CSV file with the biencoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed108ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "python dense_retriever.py \\\n",
    "    model_file=\"/data/SleepQA/DPR-main/outputs/2023-05-08/14-14-01/train_dense_encoder/dpr_biencoder.19\"\\\n",
    "    encoded_ctx_files=[\"/data/SleepQA/models/processed/encoder-clinical_0\"] \\\n",
    "    out_file=\"/data/SleepQA/models/processed/retriever-clinical.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f6bfaa",
   "metadata": {},
   "source": [
    "Finally, I saved the answers with the extractvie reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d8f74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m torch.distributed.launch --nproc_per_node=4 \\\n",
    "  train_extractive_reader.py \\\n",
    "  encoder.sequence_length=300 \\\n",
    "  passages_per_question_predict=100 \\\n",
    "  eval_top_docs=[10,20,40,50,80,100] \\\n",
    "  dev_files=\"/data/SleepQA/data/training/oracle/sleep-dev.json\"\\\n",
    "  train.dev_batch_size=16 \\\n",
    "  model_file=\"/data/SleepQA/DPR-main/outputs/2023-05-08/09-02-18/ClinicalBERT/reader/dpr_extractive_reader.10.500\" \\\n",
    "  prediction_results_file=\"/data/SleepQA/models/processed/reader-clinical.csv\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0ae565",
   "metadata": {},
   "source": [
    "\n",
    "This is the part of the results file. \n",
    "prediction_results_file=\"/data/SleepQA/models/processed/reader-clinical.csv\"\n",
    "```\n",
    "    {\n",
    "        \"question\": \"how are flippable mattresses constructed?\",\n",
    "        \"gold_answers\": [\n",
    "            \"using a different comfort layer on each side of the support core, allowing either side of the mattress to be used as the top\"\n",
    "        ],\n",
    "        \"predictions\": [\n",
    "            {\n",
    "                \"top_k\": 10,\n",
    "                \"prediction\": {\n",
    "                    \"text\": \"using a different comfort layer on each side of the support core\",\n",
    "                    \"score\": 21.362292289733887,\n",
    "                    \"relevance_score\": 3.7556169033050537,\n",
    "                    \"passage_idx\": 0,\n",
    "                    \"passage\": \"flippable mattresses are constructed using a different comfort layer on each side of the support core, allowing either side of the mattress to be used as the top. most flippable mattresses have a different firmness level on each side. in flippable mattresses, the support core consists of the firmer layers in the middle of the mattress, as well as the comfort layers from the side that's placed face - down. the vast majority of mattresses have a support core containing either steel coils, high - density polyfoam, or latex. more rarely, shoppers may come across a model containing air or water chambers in the support core.\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"top_k\": 20,\n",
    "                \"prediction\": {\n",
    "                    \"text\": \"using a different comfort layer on each side of the support core\",\n",
    "                    \"score\": 21.362292289733887,\n",
    "                    \"relevance_score\": 3.7556169033050537,\n",
    "                    \"passage_idx\": 0,\n",
    "                    \"passage\": \"flippable mattresses are constructed using a different comfort layer on each side of the support core, allowing either side of the mattress to be used as the top. most flippable mattresses have a different firmness level on each side. in flippable mattresses, the support core consists of the firmer layers in the middle of the mattress, as well as the comfort layers from the side that's placed face - down. the vast majority of mattresses have a support core containing either steel coils, high - density polyfoam, or latex. more rarely, shoppers may come across a model containing air or water chambers in the support core.\"\n",
    "                }\n",
    "            },\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00bce49",
   "metadata": {},
   "source": [
    "Then, I converted the DPR checkpoints to the PyTorch model.\n",
    "This stage is processed in `models` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dfc963",
   "metadata": {},
   "outputs": [],
   "source": [
    "python convert_dpr_original_checkpoint_to_pytorch.py --type question_encoder --src pipeline1/dpr_biencoder.19 --dest pytorch/question_encoder\n",
    "\n",
    "python convert_dpr_original_checkpoint_to_pytorch.py --type reader --src pipeline1_baseline/cp_models/dpr_extractive_reader.7.59 --dest pytorch/reader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef897855",
   "metadata": {},
   "source": [
    "\n",
    "I made the QA pipeline system and evaluate this using the results csv file and PyTorch model.\n",
    "This stage is processed in `models` and `eval` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b71fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "python qa_system.py\n",
    "python eval/__main__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2863c5",
   "metadata": {},
   "source": [
    "\n",
    "### 8. Pretrained model\n",
    "The size of the pretrained models is too big (above 100GB) so that I could not upload it.\n",
    "\n",
    "### 9. Table of results\n",
    "This is the results of two models.\n",
    "|Role|Model|Batch Size|Learning rate|Num train epochs|Avg runtime for each epoch|EM score|\n",
    "|---|---|---|---|---|---|---|\n",
    "|Biencoder|Clinical BERT|32|2e-5|20|4min 55sec||\n",
    "|Extractive Reader|Clinical BERT|32|1e-5|20|2min 24sec|53.60|\n",
    "|Biencoder|BioBERT|32|2e-5|20|4min 47sec||\n",
    "|Extractive Reader|BioBERT|32|1e-5|20|2min 32sec|58.40|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec169ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
